{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4970a8e",
   "metadata": {},
   "source": [
    "### Data clearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b3dd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Finding invalid Station Id\\nstation = []\\nstation = location['Station.Id'].values.tolist()\\n\\ndef find_missing(list):\\n    return [i for x, y in zip(station, station[1:]) \\n        for i in range(x + 1, y) if y - x > 1]\\n\\nmissing = find_missing(station)\\nmissing\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Finding invalid Station Id\n",
    "station = []\n",
    "station = location['Station.Id'].values.tolist()\n",
    "\n",
    "def find_missing(list):\n",
    "    return [i for x, y in zip(station, station[1:]) \n",
    "        for i in range(x + 1, y) if y - x > 1]\n",
    "\n",
    "missing = find_missing(station)\n",
    "missing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba6ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# delete values if Station Id is NOT inside the list 'missing'\n",
    "dataset = dataset[~dataset['Station Id'].isin(missing)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d8f48",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# create a model\n",
    "# and call data in loop for training\n",
    "\n",
    "#model = keras.Sequential()\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "                        #len(location['Station.Id'])\n",
    "for i in range(1, 10):\n",
    "  \n",
    "    neural_network_model = keras.Sequential([\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    #layers.Dropout(0.1),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    #layers.Dropout(0.1),\n",
    "    layers.Dense(1, activation ='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    #X = df[i]['date'].values.reshape(-1,1) # reshape to make it two-dimentional\n",
    "    #y = df[i]['In'].values # Predict\n",
    "    \n",
    "    X = df[i].values[:, 6:11]  #'avg_temp','avg_temp_feel','avg_humidity','avg_windSpeed','date'\n",
    "    y = df[i].values[:, 0:1] # 'In'\n",
    "    \n",
    "    # split into input (train) and output (test) variables for each of the datasets\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    #Performing Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    #y = scaler.transform(y)\n",
    "    \n",
    "    neural_network_model.compile(optimizer ='adam', loss ='binary_crossentropy', metrics = ['accuracy'])\n",
    "    neural_network_model.fit(X, y, epochs = 10, batch_size = 10)\n",
    "\n",
    "    # evaluate the keras model\n",
    "    _, accuracy = neural_network_model.evaluate(X, y)\n",
    "    print('Accuracy: %.2f' % (accuracy * 100))\n",
    "    \n",
    "    # make probability predictions with the model\n",
    "    predictions = neural_network_model.predict(X)\n",
    "    print(predictions)\n",
    "    # summarize the first 5 cases\n",
    "    #for i in range(5):\n",
    "    #    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# create a model\n",
    "# and call data in loop for training\n",
    "\n",
    "#model = keras.Sequential()\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dropout(0.2))\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "#model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "                        #len(location['Station.Id'])\n",
    "for i in range(1, 10):\n",
    "  \n",
    "    neural_network_model = keras.Sequential([\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    #layers.Dropout(0.1),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    #layers.Dropout(0.1),\n",
    "    layers.Dense(1, activation ='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    #X = df[i]['date'].values.reshape(-1,1) # reshape to make it two-dimentional\n",
    "    #y = df[i]['In'].values # Predict\n",
    "    \n",
    "    X = df[i].values[:, 6:11]  #'avg_temp','avg_temp_feel','avg_humidity','avg_windSpeed','date'\n",
    "    y = df[i].values[:, 0:1] # 'In'\n",
    "    \n",
    "    # split into input (train) and output (test) variables for each of the datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    #Performing Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    #X_train = scaler.fit_transform(X_train)\n",
    "    #X_test = scaler.transform(X_test)\n",
    "    \n",
    "    neural_network_model.compile(optimizer ='adam', loss ='binary_crossentropy', metrics = ['accuracy'])\n",
    "    #neural_network_model.fit(X, y, epochs = 10)\n",
    "    \n",
    "    # for plotting \n",
    "    hist = neural_network_model.fit(X_train, y_train, batch_size = 32, epochs = 10, validation_data = (X_test, y_test))\n",
    "    \n",
    "    #X_train = scaler.fit_transform(X_train)\n",
    "    #X_test = scaler.transform(X_test)\n",
    "    \n",
    "    #from keras.utils.vis_utils import plot_model\n",
    "    #plot_model(neural_network_model, show_shapes = True, rankdir = \"LR\")\n",
    "    \n",
    "    # Model loss\n",
    "    plt.title('Model loss')\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Model accuracy\n",
    "    plt.title('Model accuracy')\n",
    "    plt.plot(hist.history['accuracy'])\n",
    "    plt.plot(hist.history['val_accuracy'])\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Val'])\n",
    "    plt.show()\n",
    "    \n",
    "    ###\n",
    "    # when mak- https://www.freecodecamp.org/news/how-to-build-your-first-neural-network-to-predict-house-prices-with-keras-f8db83049159/\n",
    "- https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "- https://www.tensorflow.org/tutorials/images/cnn\n",
    "- https://www.analyticsvidhya.com/blog/2021/10/implementing-artificial-neural-networkclassification-in-python-from-scratch/ing prediction\n",
    "    # X[i] or X_test[i] => make sure to really understand the differences \n",
    "    # y[i] or y_test[i] => make sure to really understand the differences \n",
    "    ###\n",
    "    \n",
    "    # make probability predictions with the model\n",
    "    predictions = neural_network_model.predict(X)\n",
    "    # round predictions \n",
    "    rounded = [round(x[0]) for x in predictions]\n",
    "    # summarize the first 5 cases\n",
    "    for i in range(5):\n",
    "        print('%s => %d (expected %d)' % (X[i].tolist(), rounded[i], y_test[i]))\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb2550",
   "metadata": {},
   "source": [
    "- https://www.freecodecamp.org/news/how-to-build-your-first-neural-network-to-predict-house-prices-with-keras-f8db83049159/\n",
    "- https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "- https://www.tensorflow.org/tutorials/images/cnn\n",
    "- https://www.analyticsvidhya.com/blog/2021/10/implementing-artificial-neural-networkclassification-in-python-from-scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24450bac",
   "metadata": {},
   "source": [
    "## Visualisation of the map\n",
    "\n",
    "### think how you would do for different days \n",
    "### SOLUTION: have something like drop down list for selection of days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Function to change colors\n",
    "\n",
    "def color_change(c):\n",
    "    if(c < 15):\n",
    "        return('red')\n",
    "    elif(15 <= c < 30):\n",
    "        return('orange')\n",
    "    else:\n",
    "        return('green')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Create base map\n",
    "\n",
    "cap = dataset['In']\n",
    "date = dataset.index\n",
    "lat = dataset['latitude']\n",
    "lon = dataset['longitude']\n",
    "\n",
    "# make latitude and longitude into a list of tuples\n",
    "loc = dataset[['latitude', 'longitude']].copy()\n",
    "tuples = loc.to_records(index=False)\n",
    "locations = list(tuples)\n",
    "\n",
    "London = [51.506949, -0.122876]\n",
    "map = folium.Map(location = London,\n",
    "                 zoom_start = 12, \n",
    "                 tiles = \"CartoDB positron\")\n",
    "marker_cluster = MarkerCluster(locations).add_to(map)\n",
    "\n",
    "# Plot markers\n",
    "\n",
    "for _lat, _lon, _cap, _date in zip(lat, lon, cap, date):\n",
    "    folium.CircleMarker(location = [_lat, _lon], \n",
    "                        radius = 9, \n",
    "                        popup = \"(\"+ str(_cap) +\")\" + str(_date),\n",
    "                        fill_color = color_change(_cap), \n",
    "                        color = \"gray\", \n",
    "                        fill_opacity = 0.9).add_to(marker_cluster)\n",
    "\"\"\"- https://towardsdatascience.com/visualizing-bike-mobility-in-london-using-interactive-maps-for-absolute-beginners-3b9f55ccb59\n",
    "- https://www.analyticsvidhya.com/blog/2020/06/guide-geospatial-analysis-folium-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d176408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748dfbf",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/visualizing-bike-mobility-in-london-using-interactive-maps-for-absolute-beginners-3b9f55ccb59\n",
    "- https://www.analyticsvidhya.com/blog/2020/06/guide-geospatial-analysis-folium-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
